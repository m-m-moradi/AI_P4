{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4726eedb-4405-4d7c-aa40-8498abfa2a43",
   "metadata": {},
   "source": [
    "## Importing datasets and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0405e765-d2fe-4f38-b76a-77a52906f48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 0.0060389041900634766\n",
      "number of lines in neg_lines: 5331\n",
      "example of line in neg_lines: simplistic , silly and tedious . \n",
      "\n",
      "number of lines in pos_lines: 5331\n",
      "example of line in pos_lines: the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "negative_file_adr = '../dataset/rt-polarity.neg'\n",
    "positive_file_adr = '../dataset/rt-polarity.pos'\n",
    "\n",
    "# reading dataset\n",
    "start = time.time()\n",
    "with open(negative_file_adr, 'r') as neg_file:\n",
    "    neg_lines = neg_file.readlines()\n",
    "    \n",
    "    \n",
    "with open(positive_file_adr, 'r') as pos_file:\n",
    "    pos_lines = pos_file.readlines()\n",
    "end = time.time()\n",
    "\n",
    "print(f'elapsed time: {end - start}')\n",
    "\n",
    "print(f'number of lines in neg_lines: {len(neg_lines)}')\n",
    "print(f'example of line in neg_lines: {neg_lines[0]}')\n",
    "print(f'number of lines in pos_lines: {len(pos_lines)}')\n",
    "print(f'example of line in pos_lines: {pos_lines[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b144e64a-a9cf-4026-ab86-3d73ea6dc260",
   "metadata": {},
   "source": [
    "## Language Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57989b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import traceback\n",
    "\n",
    "class LanguageModel:\n",
    "    def __init__(self, lines, weights, test_dataset_count, online=True):\n",
    "        self.lines = lines         # List of strings (each string is a line in input file)\n",
    "        self.test_dataset = None   # List of lists (each list is a list of words in line)\n",
    "        self.train_dataset = None  # List of lists (each list is a list of words in line)\n",
    "        self.word_count  = None    # number of words in train_dataset\n",
    "        self.token_count = None    # number of types\n",
    "        self.interpolation_weights = weights\n",
    "        self.test_dataset_count = test_dataset_count\n",
    "        self.online = online\n",
    "        \n",
    "        self.unigram_count_dict = None\n",
    "        self.bigram_count_dict = None        \n",
    "        self.interpolation_matrix = None\n",
    "        \n",
    "        # preparing train and test dataset\n",
    "        self._make_train_and_test_dataset()\n",
    "        \n",
    "        # making count dictionaries - both of them are ordered dictionary \n",
    "        self.unigram_count_dict = self._make_unigram_dictionary(self.train_dataset)\n",
    "        self.bigram_count_dict = self._make_bigram_dictionary(self.train_dataset)\n",
    "    \n",
    "        # initialization word_count and token_count and ckeck that count dictionaries correctly created\n",
    "        unigram_word_count = sum([value for key, value in self.unigram_count_dict.items()])\n",
    "        dataset_word_count = sum([len(word_list) for word_list in self.train_dataset])\n",
    "        assert unigram_word_count == dataset_word_count, 'something in wrong in unigram count dictioary creation'\n",
    "        self.word_count = dataset_word_count\n",
    "        self.token_count = len(self.unigram_count_dict)\n",
    "        \n",
    "        bigram_word_count = sum([value for key, value in self.bigram_count_dict.items()])\n",
    "        dataset_double_combination_count = sum([len(word_list) - 1 for word_list in self.train_dataset])\n",
    "        assert bigram_word_count == dataset_double_combination_count, 'something is wrong in bigram count dictionary creation'\n",
    "        \n",
    "        \n",
    "        # making unigram dataframe\n",
    "        unigram_probs = []\n",
    "        for word in self.unigram_count_dict:\n",
    "            unigram_probs.append(self._smoothed_unigram_probability(word))\n",
    "            \n",
    "        unigram_data = {\n",
    "            'count': list(self.unigram_count_dict.values()),\n",
    "            'prob': unigram_probs,\n",
    "        }\n",
    "        self.unigram_df = pd.DataFrame(unigram_data, index=list(self.unigram_count_dict.keys()))\n",
    "               \n",
    "        \n",
    "        if not online:\n",
    "            # making bigram dataframe\n",
    "            bigram_probs = []\n",
    "            for combination in self.bigram_count_dict:\n",
    "                bigram_probs.append(self._smoothed_bigram_probability(combination))\n",
    "\n",
    "            rows = len(bigram_probs)\n",
    "            ## first column in matrix - bigram probabilities\n",
    "            bigram_col  = np.array(bigram_probs).reshape(rows, 1)\n",
    "\n",
    "            ## socond column in matrix - probabilites of second word in combinaition\n",
    "            unigram_col = []\n",
    "            for combination in self.bigram_count_dict:\n",
    "                unigram_col.append(self.get_or_calculate_word_probability(combination[1]))\n",
    "            unigram_col = np.array(unigram_col).reshape(rows, 1)\n",
    "\n",
    "            ## third clumn in matrix - epsilon\n",
    "            epsilon_col = np.array([self.interpolation_weights[3] for _ in range(rows)]).reshape(rows, 1)\n",
    "\n",
    "            ## making martix\n",
    "            self.interpolation_matrix = np.hstack((bigram_col, unigram_col, epsilon_col))\n",
    "\n",
    "            bigram_data = {\n",
    "                'count': list(self.bigram_count_dict.values()),\n",
    "                'prob': bigram_probs,\n",
    "                'inter_prob': self._matrix_interpolation_calculator(self.interpolation_weights)\n",
    "            }\n",
    "            self.bigram_df = pd.DataFrame(bigram_data, index=pd.MultiIndex.from_tuples(list(self.bigram_count_dict.keys())))\n",
    "\n",
    "        \n",
    "    def _make_train_and_test_dataset(self):\n",
    "        # selecting some lines for testing\n",
    "        test_dataset_lines  = np.random.choice(self.lines, self.test_dataset_count, replace=False)\n",
    "        train_dataset_lines = [n for n in self.lines if n not in test_dataset_lines]\n",
    "        \n",
    "        self.test_dataset  = self._clean(test_dataset_lines)\n",
    "        self.train_dataset = self._clean(train_dataset_lines)\n",
    "        \n",
    "    \n",
    "    # gets list of string (lines) and returns a list of 'list of words'(=line)\n",
    "    @staticmethod\n",
    "    def _clean(lines): \n",
    "        start_symbol = '<s>'\n",
    "        end_symbol = '</s>'\n",
    "        cleaned_up = []\n",
    "\n",
    "        for line in lines:\n",
    "            line = line.translate({ord(x): ' ' for x in string.punctuation})\n",
    "            line = line.translate({ord(x): ' ' for x in line if x not in string.printable})\n",
    "            line = line.split()\n",
    "            line.insert(0, start_symbol)\n",
    "            line.append(end_symbol)\n",
    "            cleaned_up.append(line)\n",
    "\n",
    "        return cleaned_up\n",
    "\n",
    "    def _make_unigram_dictionary(self, dataset):\n",
    "        dictionary = {}\n",
    "        for line in dataset:\n",
    "            for word in line:\n",
    "                if word in dictionary:\n",
    "                    dictionary[word] += 1\n",
    "                else:\n",
    "                    dictionary[word] = 1\n",
    "        return OrderedDict(sorted(dictionary.items()))\n",
    "\n",
    "    \n",
    "    def _make_bigram_dictionary(self, dataset):\n",
    "        dictionary = {}\n",
    "        for line in dataset:\n",
    "            for i in range(len(line) - 1):\n",
    "                first_word  = line[i]\n",
    "                second_word = line[i+1]\n",
    "                combination = (first_word, second_word)\n",
    "                if combination in dictionary:\n",
    "                    dictionary[combination] += 1\n",
    "                else:\n",
    "                    dictionary[combination] = 1\n",
    "\n",
    "        return OrderedDict(sorted(dictionary.items()))\n",
    "    \n",
    "    \n",
    "    # using Laplace smoothing\n",
    "    def _smoothed_unigram_probability(self, word):\n",
    "        count = 0\n",
    "        try: count = self.unigram_count_dict[word]\n",
    "        except: pass\n",
    "        \n",
    "        return (count + 1) / (self.word_count + self.word_count)\n",
    "    \n",
    "    \n",
    "    # using laplace smoothing\n",
    "    def _smoothed_bigram_probability(self, combination):        \n",
    "        first_word  = combination[0]\n",
    "        second_word = combination[1]\n",
    "        \n",
    "        count_combination = 0\n",
    "        try: count_combination = self.bigram_count_dict[combination]\n",
    "        except: pass\n",
    "        \n",
    "        count_first_word = 0\n",
    "        try: count_first_word = unigram_count_dict[first_word]\n",
    "        except: pass\n",
    "        \n",
    "        return (count_combination + 1) / (count_first_word + self.token_count)\n",
    "    \n",
    "    \n",
    "    def _interpolated_bigram_probability(self, combination):\n",
    "        assert self.interpolation_weights is not None, 'please set interpolation weights before calculations'\n",
    "        l3 = self.interpolation_weights[0]\n",
    "        l2 = self.interpolation_weights[1]\n",
    "        l1 = self.interpolation_weights[2]\n",
    "        e  = self.interpolation_weights[3]\n",
    "        \n",
    "        first_word  = combination[0]\n",
    "        second_word = combination[1]\n",
    "        \n",
    "        return l3 * self._smoothed_bigram_probability(combination) + \\\n",
    "               l2 * self._smoothed_unigram_probability(second_word) + \\\n",
    "               l1 * e\n",
    "    \n",
    "\n",
    "    def _matrix_interpolation_calculator(self, weights):\n",
    "        return np.matmul(self.interpolation_matrix, np.array(weights[:3]))\n",
    "    \n",
    "    \n",
    "    def get_or_calculate_word_probability(self, word):\n",
    "        if word in self.unigram_count_dict and not self.online:\n",
    "            return self.unigram_df.loc[word].at['prob']\n",
    "        return self._smoothed_unigram_probability(word)\n",
    "    \n",
    "    \n",
    "    def get_or_calculate_combination_probability(self, combination):\n",
    "        if combination in self.bigram_count_dict and not self.online:\n",
    "            return self.bigram_df.loc[combination].at['inter_prob']\n",
    "        return self._interpolated_bigram_probability(combination)\n",
    "    \n",
    "    \n",
    "    def sentence_probability_bigram(self, sentence, log=False):\n",
    "        total_probability = self.get_or_calculate_word_probability(sentence[0])\n",
    "        if log: print(f'w0  : {sentence[0]:<47}, prob:{total_probability:<30}')\n",
    "\n",
    "        for i in range(1, len(sentence) - 1):\n",
    "            first_word = sentence[i]\n",
    "            second_word = sentence[i+1]\n",
    "            p = self.get_or_calculate_combination_probability((first_word, second_word))\n",
    "            total_probability *= p\n",
    "\n",
    "            if log: print(f'w{i:<3}: {first_word:<20}, w{i+1:<3}:{second_word:<20}, prob:{p:<30}')\n",
    "\n",
    "        if log: print(f'FINAL PROBABILITY: {total_probability:}\\n')\n",
    "        return total_probability\n",
    "    \n",
    "    \n",
    "    def sentence_probability_unigram(self, sentence, log=False):\n",
    "        total_probability = self.get_or_calculate_word_probability(sentence[0])\n",
    "        if log: print(f'w0  : {sentence[0]:<20}, prob:{total_probability:<20}')\n",
    "            \n",
    "        for i in range(1, len(sentence) - 1):\n",
    "            word = sentence[i]\n",
    "            p = self.get_or_calculate_word_probability(word)\n",
    "            total_probability *= p\n",
    "            \n",
    "            if log: print(f'w{i:<3}: {word:<20}, prob:{total_probability:<20}')\n",
    "                \n",
    "        if log: print(f'FINAL PROBABILITY: {total_probability:}\\n')\n",
    "        return total_probability\n",
    "\n",
    "    \n",
    "    def check_on_dataset(self, test_dataset, log=False, mode='bigram'):\n",
    "        if mode == 'bigram':\n",
    "            probabilities = []\n",
    "            for sentence in test_dataset:\n",
    "                probabilities.append(self.sentence_probability_bigram(sentence, log))\n",
    "            return probabilities\n",
    "        else:\n",
    "            probabilities = []\n",
    "            \n",
    "            for sentence in test_dataset:\n",
    "                probabilities.append(self.sentence_probability_unigram(sentence, log))\n",
    "            return probabilities \n",
    "    \n",
    "    def set_interpolation_weights(self, weights, update_interpolations=False):\n",
    "        self.interpolation_weights = weights\n",
    "        if not self.online and update_interpolations:\n",
    "            self.bigram_df['inter_prob'] = self._matrix_interpolation_calculator(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47e012d7-6c6e-4636-936c-5039b11bbb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_test(language_model0, language_model1, log=False, mode='bigram'):\n",
    "\n",
    "    successful_detection = 0\n",
    "    # for testing the accuracy of language model 0\n",
    "    # see how confident it is for detecting its own sentences \n",
    "    # if language 1 more confidentely says the sentence belongs to itself, this is a incorrect detection for language model 0\n",
    "    start = time.time()\n",
    "    lang0_probs_on_test_dataset0 = language_model0.check_on_dataset(language_model0.test_dataset, log=log, mode=mode)\n",
    "    lang1_probs_on_test_dataset0 = language_model1.check_on_dataset(language_model0.test_dataset, log=log, mode=mode)\n",
    "    \n",
    "    # for testing the accuracy of language model 1\n",
    "    # see how confident it is for detecting tis own sentences \n",
    "    # if language 0 more confidentely says the sentence belongs to itself, this is a incorrect detection for language model 1\n",
    "    lang0_probs_on_test_dataset1 = language_model0.check_on_dataset(language_model1.test_dataset, log=log, mode=mode)\n",
    "    lang1_probs_on_test_dataset1 = language_model1.check_on_dataset(language_model1.test_dataset, log=log, mode=mode)\n",
    "    end = time.time()\n",
    "    \n",
    "#     print(end - start)\n",
    "    \n",
    "    assert len(lang0_probs_on_test_dataset0) == len(lang1_probs_on_test_dataset0), 'something is wrong in testing'\n",
    "    assert len(lang0_probs_on_test_dataset1) == len(lang1_probs_on_test_dataset1), 'something is wrong in testing'\n",
    "    testcase_count_in_test_dataset0 = len(lang0_probs_on_test_dataset0)\n",
    "    testcase_count_in_test_dataset1 = len(lang0_probs_on_test_dataset1)\n",
    "\n",
    "    \n",
    "    # see how confident language model 0 is for detecting its own sentences \n",
    "    correct_detection_by_language_model0 = 0\n",
    "    for i in range(testcase_count_in_test_dataset0):\n",
    "        if lang0_probs_on_test_dataset0[i] >= lang1_probs_on_test_dataset0[i]:\n",
    "            # language model 0 is more confident to detecting its sentences than language model 1\n",
    "            correct_detection_by_language_model0 += 1\n",
    "            \n",
    "            \n",
    "    # see how confident language model 1 is for detecting its own sentences \n",
    "    correct_detection_by_language_model1 = 0\n",
    "    for i in range(testcase_count_in_test_dataset1):\n",
    "        if lang0_probs_on_test_dataset1[i] <= lang1_probs_on_test_dataset1[i]:\n",
    "            # language model 1 is more confident to detecting its sentences than language model 0\n",
    "            correct_detection_by_language_model1 += 1\n",
    "\n",
    "    language_model0_accuracy = correct_detection_by_language_model0 / testcase_count_in_test_dataset0\n",
    "    language_model1_accuracy = correct_detection_by_language_model1 / testcase_count_in_test_dataset1\n",
    "    \n",
    "    return language_model0_accuracy, language_model1_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805a62e5-a9ce-43f5-a5eb-9dc56946705c",
   "metadata": {},
   "source": [
    "## Making Languages Models (Making full probability tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45c5ba09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time : 18.77100133895874\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "weights = np.array([0.09, 0.9, 0.01, 0.01])\n",
    "language_model0_offline = LanguageModel(neg_lines, weights, 500, online=False)\n",
    "language_model1_offline = LanguageModel(pos_lines, weights, 500, online=False)\n",
    "end = time.time()\n",
    "print(f'elapsed time : {end - start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df87d221-73f2-456f-8041-b3bf6402274a",
   "metadata": {},
   "source": [
    "### Bigram Model Test (offline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9502f75c-cfb3-4b6d-9666-bcc9cbad7a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time : 4.36603856086731\n",
      "language model 0 accuracy = 73.4\n",
      "language model 1 accuracy = 76.6\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model0_ac, model1_ac = accuracy_test(language_model0_offline, language_model1_offline, mode='bigram', log=False)\n",
    "end = time.time()\n",
    "print(f'elapsed time : {end - start}')\n",
    "print(f'language model 0 accuracy = {np.round(model0_ac * 100, 3)}')\n",
    "print(f'language model 1 accuracy = {np.round(model1_ac * 100, 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd010c2-8c21-4819-91dc-7d89d591486d",
   "metadata": {},
   "source": [
    "### Unigram Model Test (offline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7206494d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time : 4.635961055755615\n",
      "language model 0 accuracy = 77.6\n",
      "language model 1 accuracy = 75.6\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model0_ac, model1_ac = accuracy_test(language_model0_offline, language_model1_offline, mode='unigram', log=False)\n",
    "end = time.time()\n",
    "print(f'elapsed time : {end - start}')\n",
    "print(f'language model 0 accuracy = {np.round(model0_ac * 100, 3)}')\n",
    "print(f'language model 1 accuracy = {np.round(model1_ac * 100, 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f95037-446b-454f-8bdd-5f2b3944e5bc",
   "metadata": {},
   "source": [
    "## Making Languages Models (without making probability tables initially)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd3ff938-30ee-466d-a8bf-96ef35001b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time : 1.083047866821289\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "weights = np.array([0.09, 0.9, 0.01, 0.01])\n",
    "language_model0_online = LanguageModel(neg_lines, weights, 500, online=True)\n",
    "language_model1_online = LanguageModel(pos_lines, weights, 500, online=True)\n",
    "end = time.time()\n",
    "print(f'elapsed time : {end - start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b26542-6cb2-42f8-9912-c94c472c5007",
   "metadata": {},
   "source": [
    "### Bigram Model Test (online)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a74eae85-fc08-445c-917b-3325496e4339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time : 0.16803789138793945\n",
      "language model 0 accuracy = 74.8\n",
      "language model 1 accuracy = 74.8\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model0_ac, model1_ac = accuracy_test(language_model0_online, language_model1_online, mode='bigram', log=False)\n",
    "end = time.time()\n",
    "print(f'elapsed time : {end - start}')\n",
    "print(f'language model 0 accuracy = {np.round(model0_ac * 100, 3)}')\n",
    "print(f'language model 1 accuracy = {np.round(model1_ac * 100, 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606f54f9-779f-45a5-af9b-e465f3c2ecd7",
   "metadata": {},
   "source": [
    "### Unigram Model Test (online)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e3c87c5-4030-4420-89e5-2b3ffeddf793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time : 0.04903721809387207\n",
      "language model 0 accuracy = 79.8\n",
      "language model 1 accuracy = 76.4\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model0_ac, model1_ac = accuracy_test(language_model0_online, language_model1_online, mode='unigram', log=False)\n",
    "end = time.time()\n",
    "print(f'elapsed time : {end - start}')\n",
    "print(f'language model 0 accuracy = {np.round(model0_ac * 100, 3)}')\n",
    "print(f'language model 1 accuracy = {np.round(model1_ac * 100, 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad10c7e-3681-4490-848b-97cc26dfa344",
   "metadata": {},
   "source": [
    "### Probability calculations log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "138470bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<s>', 'this', 'is', 'some', 'test', 'text', '</s>']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LanguageModel._clean(['this is some test text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aae62a5f",
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram probability\n",
      "Language Model 0\n",
      "w0  : <s>                                            , prob:0.02345039116339565           \n",
      "w1  : this                , w2  :is                  , prob:0.007370558142952268          \n",
      "w2  : is                  , w3  :some                , prob:0.0007887578434239133         \n",
      "w3  : some                , w4  :test                , prob:0.00015105473935309613        \n",
      "w4  : test                , w5  :text                , prob:0.00013358342143334772        \n",
      "w5  : text                , w6  :</s>                , prob:0.02121272849160981           \n",
      "FINAL PROBABILITY: 5.835493782128972e-17\n",
      "\n",
      "Language Model 1\n",
      "w0  : <s>                                            , prob:0.02340518285299104           \n",
      "w1  : this                , w2  :is                  , prob:0.0076855714837474375         \n",
      "w2  : is                  , w3  :some                , prob:0.0007396111896946144         \n",
      "w3  : some                , w4  :test                , prob:0.00012493451253307408        \n",
      "w4  : test                , w5  :text                , prob:0.00011621569441730756        \n",
      "w5  : text                , w6  :</s>                , prob:0.021172161443993476          \n",
      "FINAL PROBABILITY: 4.089818950198124e-17\n",
      "\n",
      "Unigram probability\n",
      "Language Model 0\n",
      "w0  : <s>                 , prob:0.02345039116339565 \n",
      "w1  : this                , prob:8.000710979688206e-05\n",
      "w2  : is                  , prob:5.800993052071409e-07\n",
      "w3  : some                , prob:4.3918764007296213e-10\n",
      "w4  : test                , prob:2.131440801705211e-14\n",
      "w5  : text                , prob:6.206513312285862e-19\n",
      "FINAL PROBABILITY: 6.206513312285862e-19\n",
      "\n",
      "Language Model 1\n",
      "w0  : <s>                 , prob:0.02340518285299104 \n",
      "w1  : this                , prob:6.904217174846958e-05\n",
      "w2  : is                  , prob:5.163531759730542e-07\n",
      "w3  : some                , prob:3.626602592205999e-10\n",
      "w4  : test                , prob:7.026597417691449e-15\n",
      "w5  : text                , prob:6.807069428618502e-20\n",
      "FINAL PROBABILITY: 6.807069428618502e-20\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.807069428618502e-20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Bigram probability\")\n",
    "print(\"Language Model 0\")\n",
    "language_model0_online.sentence_probability_bigram(LanguageModel._clean(['this is some test text'])[0], log=True)\n",
    "print(\"Language Model 1\")\n",
    "language_model1_online.sentence_probability_bigram(LanguageModel._clean(['this is some test text'])[0], log=True)\n",
    "\n",
    "print(\"Unigram probability\")\n",
    "print(\"Language Model 0\")\n",
    "language_model0_online.sentence_probability_unigram(LanguageModel._clean(['this is some test text'])[0], log=True)\n",
    "print(\"Language Model 1\")\n",
    "language_model1_online.sentence_probability_unigram(LanguageModel._clean(['this is some test text'])[0], log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5444a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 50, time: 7.0850183963775635\n",
      "step: 100, time: 7.729002475738525\n",
      "step: 150, time: 7.327358961105347\n",
      "step: 200, time: 8.022965669631958\n",
      "step: 250, time: 7.57404088973999\n",
      "step: 300, time: 8.754998207092285\n",
      "step: 350, time: 7.6680028438568115\n",
      "step: 400, time: 6.958999156951904\n",
      "step: 450, time: 7.399195909500122\n",
      "step: 500, time: 6.932032346725464\n"
     ]
    }
   ],
   "source": [
    "test_case_count = 500\n",
    "test_dictionary_relaxed = {}\n",
    "for i in range(test_case_count):\n",
    "    scalars = np.random.random(2)\n",
    "    scalars = np.append(scalars, 0.001) # l1\n",
    "    scalars = scalars / sum(scalars)\n",
    "    scalars = np.append(scalars, 0.001) # e\n",
    "    test_dictionary_relaxed[(i, tuple(scalars))] = None\n",
    "#     print(f'testcase: {i:<4},{scalars}, SUM[:3]: {sum(scalars[:3])}')\n",
    "\n",
    "counter = 0\n",
    "total_time = 0\n",
    "start = time.time()\n",
    "for key in test_dictionary_relaxed:\n",
    "    language_model0_online.set_interpolation_weights(key[1], update_interpolations=False)\n",
    "    language_model1_online.set_interpolation_weights(key[1], update_interpolations=False)\n",
    "    pos_ac, neg_ac = accuracy_test(language_model0_online, language_model1_online, mode='bigram')\n",
    "    test_dictionary_relaxed[key] = (pos_ac, neg_ac)\n",
    "    counter += 1\n",
    "    if counter % (test_case_count / 10) == 0:\n",
    "        now = time.time()\n",
    "        print(f'step: {counter}, time: {now - start}')\n",
    "        total_time += now\n",
    "        start = time.time()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee3d12a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testcase: 414 [l3: 0.0801][l2: 0.9188][l1: 0.0011][e: 0.001 ] ==> [positive accuracy: 0.786 ][negative accuracy: 0.788 ]\n",
      "testcase: 436 [l3: 0.172 ][l2: 0.827 ][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.784 ][negative accuracy: 0.788 ]\n",
      "testcase: 96  [l3: 0.3175][l2: 0.6816][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.782 ][negative accuracy: 0.788 ]\n",
      "testcase: 185 [l3: 0.3166][l2: 0.6826][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.782 ][negative accuracy: 0.788 ]\n",
      "testcase: 227 [l3: 0.1709][l2: 0.828 ][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.782 ][negative accuracy: 0.788 ]\n",
      "testcase: 267 [l3: 0.2341][l2: 0.7651][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.782 ][negative accuracy: 0.788 ]\n",
      "testcase: 274 [l3: 0.182 ][l2: 0.8164][l1: 0.0016][e: 0.001 ] ==> [positive accuracy: 0.782 ][negative accuracy: 0.788 ]\n",
      "testcase: 333 [l3: 0.1761][l2: 0.823 ][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.782 ][negative accuracy: 0.788 ]\n",
      "testcase: 336 [l3: 0.1148][l2: 0.8842][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.782 ][negative accuracy: 0.788 ]\n",
      "testcase: 366 [l3: 0.0877][l2: 0.911 ][l1: 0.0013][e: 0.001 ] ==> [positive accuracy: 0.784 ][negative accuracy: 0.786 ]\n",
      "testcase: 389 [l3: 0.1747][l2: 0.8245][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.782 ][negative accuracy: 0.788 ]\n",
      "testcase: 397 [l3: 0.2304][l2: 0.7687][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.782 ][negative accuracy: 0.788 ]\n",
      "testcase: 420 [l3: 0.2341][l2: 0.7648][l1: 0.0011][e: 0.001 ] ==> [positive accuracy: 0.782 ][negative accuracy: 0.788 ]\n",
      "testcase: 433 [l3: 0.1668][l2: 0.8322][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.782 ][negative accuracy: 0.788 ]\n",
      "testcase: 448 [l3: 0.1837][l2: 0.8153][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.782 ][negative accuracy: 0.788 ]\n",
      "testcase: 472 [l3: 0.1145][l2: 0.8845][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.782 ][negative accuracy: 0.788 ]\n",
      "testcase: 476 [l3: 0.0889][l2: 0.9101][l1: 0.0011][e: 0.001 ] ==> [positive accuracy: 0.784 ][negative accuracy: 0.786 ]\n",
      "testcase: 3   [l3: 0.3104][l2: 0.6888][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.782 ][negative accuracy: 0.786 ]\n",
      "testcase: 34  [l3: 0.0789][l2: 0.9186][l1: 0.0025][e: 0.001 ] ==> [positive accuracy: 0.784 ][negative accuracy: 0.784 ]\n",
      "testcase: 53  [l3: 0.0745][l2: 0.9241][l1: 0.0014][e: 0.001 ] ==> [positive accuracy: 0.784 ][negative accuracy: 0.784 ]\n",
      "testcase: 113 [l3: 0.3075][l2: 0.6917][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.782 ][negative accuracy: 0.786 ]\n",
      "testcase: 158 [l3: 0.174 ][l2: 0.8247][l1: 0.0013][e: 0.001 ] ==> [positive accuracy: 0.782 ][negative accuracy: 0.786 ]\n",
      "testcase: 180 [l3: 0.2004][l2: 0.7983][l1: 0.0013][e: 0.001 ] ==> [positive accuracy: 0.782 ][negative accuracy: 0.786 ]\n",
      "testcase: 202 [l3: 0.1973][l2: 0.8009][l1: 0.0017][e: 0.001 ] ==> [positive accuracy: 0.782 ][negative accuracy: 0.786 ]\n",
      "testcase: 226 [l3: 0.2773][l2: 0.7215][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.78  ][negative accuracy: 0.788 ]\n",
      "testcase: 275 [l3: 0.2739][l2: 0.7247][l1: 0.0015][e: 0.001 ] ==> [positive accuracy: 0.78  ][negative accuracy: 0.788 ]\n",
      "testcase: 340 [l3: 0.321 ][l2: 0.6783][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.78  ][negative accuracy: 0.788 ]\n",
      "testcase: 343 [l3: 0.265 ][l2: 0.7326][l1: 0.0024][e: 0.001 ] ==> [positive accuracy: 0.78  ][negative accuracy: 0.788 ]\n",
      "testcase: 380 [l3: 0.0797][l2: 0.9186][l1: 0.0017][e: 0.001 ] ==> [positive accuracy: 0.784 ][negative accuracy: 0.784 ]\n",
      "testcase: 418 [l3: 0.1899][l2: 0.8091][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.782 ][negative accuracy: 0.786 ]\n",
      "testcase: 452 [l3: 0.0923][l2: 0.9065][l1: 0.0011][e: 0.001 ] ==> [positive accuracy: 0.782 ][negative accuracy: 0.786 ]\n",
      "testcase: 466 [l3: 0.279 ][l2: 0.72  ][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.78  ][negative accuracy: 0.788 ]\n",
      "testcase: 33  [l3: 0.2079][l2: 0.7909][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.782 ][negative accuracy: 0.784 ]\n",
      "testcase: 35  [l3: 0.3276][l2: 0.6715][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.78  ][negative accuracy: 0.786 ]\n",
      "testcase: 59  [l3: 0.1573][l2: 0.8418][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.78  ][negative accuracy: 0.786 ]\n",
      "testcase: 66  [l3: 0.2173][l2: 0.7811][l1: 0.0015][e: 0.001 ] ==> [positive accuracy: 0.78  ][negative accuracy: 0.786 ]\n",
      "testcase: 100 [l3: 0.1622][l2: 0.8369][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.78  ][negative accuracy: 0.786 ]\n",
      "testcase: 111 [l3: 0.2127][l2: 0.7861][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.782 ][negative accuracy: 0.784 ]\n",
      "testcase: 115 [l3: 0.2052][l2: 0.794 ][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.782 ][negative accuracy: 0.784 ]\n",
      "testcase: 129 [l3: 0.2599][l2: 0.7387][l1: 0.0014][e: 0.001 ] ==> [positive accuracy: 0.78  ][negative accuracy: 0.786 ]\n",
      "testcase: 140 [l3: 0.3096][l2: 0.6893][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.78  ][negative accuracy: 0.786 ]\n",
      "testcase: 160 [l3: 0.2803][l2: 0.7189][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.778 ][negative accuracy: 0.788 ]\n",
      "testcase: 174 [l3: 0.248 ][l2: 0.7508][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.78  ][negative accuracy: 0.786 ]\n",
      "testcase: 182 [l3: 0.0528][l2: 0.9455][l1: 0.0016][e: 0.001 ] ==> [positive accuracy: 0.786 ][negative accuracy: 0.78  ]\n",
      "testcase: 201 [l3: 0.2174][l2: 0.7811][l1: 0.0015][e: 0.001 ] ==> [positive accuracy: 0.78  ][negative accuracy: 0.786 ]\n",
      "testcase: 242 [l3: 0.0536][l2: 0.9443][l1: 0.0021][e: 0.001 ] ==> [positive accuracy: 0.786 ][negative accuracy: 0.78  ]\n",
      "testcase: 245 [l3: 0.2233][l2: 0.7757][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.782 ][negative accuracy: 0.784 ]\n",
      "testcase: 262 [l3: 0.0424][l2: 0.9562][l1: 0.0014][e: 0.001 ] ==> [positive accuracy: 0.786 ][negative accuracy: 0.78  ]\n",
      "testcase: 265 [l3: 0.106 ][l2: 0.8931][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.78  ][negative accuracy: 0.786 ]\n",
      "testcase: 268 [l3: 0.21  ][l2: 0.7885][l1: 0.0015][e: 0.001 ] ==> [positive accuracy: 0.782 ][negative accuracy: 0.784 ]\n",
      "testcase: 271 [l3: 0.1871][l2: 0.812 ][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.78  ][negative accuracy: 0.786 ]\n",
      "testcase: 279 [l3: 0.3292][l2: 0.6698][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.78  ][negative accuracy: 0.786 ]\n",
      "testcase: 280 [l3: 0.2232][l2: 0.7755][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.78  ][negative accuracy: 0.786 ]\n",
      "testcase: 305 [l3: 0.2191][l2: 0.7801][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.782 ][negative accuracy: 0.784 ]\n",
      "testcase: 315 [l3: 0.0441][l2: 0.9547][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.786 ][negative accuracy: 0.78  ]\n",
      "testcase: 330 [l3: 0.2116][l2: 0.7872][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.782 ][negative accuracy: 0.784 ]\n",
      "testcase: 337 [l3: 0.2755][l2: 0.7236][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.778 ][negative accuracy: 0.788 ]\n",
      "testcase: 345 [l3: 0.0388][l2: 0.9602][l1: 0.0011][e: 0.001 ] ==> [positive accuracy: 0.786 ][negative accuracy: 0.78  ]\n",
      "testcase: 353 [l3: 0.2225][l2: 0.776 ][l1: 0.0015][e: 0.001 ] ==> [positive accuracy: 0.78  ][negative accuracy: 0.786 ]\n",
      "testcase: 361 [l3: 0.2358][l2: 0.763 ][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.78  ][negative accuracy: 0.786 ]\n",
      "testcase: 381 [l3: 0.3273][l2: 0.672 ][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.78  ][negative accuracy: 0.786 ]\n",
      "testcase: 387 [l3: 0.3108][l2: 0.6874][l1: 0.0018][e: 0.001 ] ==> [positive accuracy: 0.78  ][negative accuracy: 0.786 ]\n",
      "testcase: 430 [l3: 0.048 ][l2: 0.9499][l1: 0.0021][e: 0.001 ] ==> [positive accuracy: 0.786 ][negative accuracy: 0.78  ]\n",
      "testcase: 453 [l3: 0.2435][l2: 0.7555][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.78  ][negative accuracy: 0.786 ]\n",
      "testcase: 469 [l3: 0.2731][l2: 0.726 ][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.778 ][negative accuracy: 0.788 ]\n",
      "testcase: 495 [l3: 0.2811][l2: 0.7181][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.778 ][negative accuracy: 0.788 ]\n",
      "testcase: 11  [l3: 0.154 ][l2: 0.8452][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.778 ][negative accuracy: 0.786 ]\n",
      "testcase: 75  [l3: 0.1195][l2: 0.8775][l1: 0.003 ][e: 0.001 ] ==> [positive accuracy: 0.78  ][negative accuracy: 0.784 ]\n",
      "testcase: 77  [l3: 0.2377][l2: 0.761 ][l1: 0.0013][e: 0.001 ] ==> [positive accuracy: 0.78  ][negative accuracy: 0.784 ]\n",
      "testcase: 92  [l3: 0.0304][l2: 0.9683][l1: 0.0013][e: 0.001 ] ==> [positive accuracy: 0.788 ][negative accuracy: 0.776 ]\n",
      "testcase: 103 [l3: 0.2784][l2: 0.7197][l1: 0.002 ][e: 0.001 ] ==> [positive accuracy: 0.778 ][negative accuracy: 0.786 ]\n",
      "testcase: 107 [l3: 0.3086][l2: 0.6903][l1: 0.0011][e: 0.001 ] ==> [positive accuracy: 0.78  ][negative accuracy: 0.784 ]\n",
      "testcase: 132 [l3: 0.2079][l2: 0.7882][l1: 0.0039][e: 0.001 ] ==> [positive accuracy: 0.778 ][negative accuracy: 0.786 ]\n",
      "testcase: 155 [l3: 0.1614][l2: 0.8377][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.778 ][negative accuracy: 0.786 ]\n",
      "testcase: 183 [l3: 0.3059][l2: 0.6928][l1: 0.0013][e: 0.001 ] ==> [positive accuracy: 0.78  ][negative accuracy: 0.784 ]\n",
      "testcase: 195 [l3: 0.2833][l2: 0.7159][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.788 ]\n",
      "testcase: 257 [l3: 0.0616][l2: 0.9368][l1: 0.0015][e: 0.001 ] ==> [positive accuracy: 0.782 ][negative accuracy: 0.782 ]\n",
      "testcase: 295 [l3: 0.3383][l2: 0.6609][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.778 ][negative accuracy: 0.786 ]\n",
      "testcase: 296 [l3: 0.2798][l2: 0.7194][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.788 ]\n",
      "testcase: 318 [l3: 0.0175][l2: 0.9814][l1: 0.0011][e: 0.001 ] ==> [positive accuracy: 0.792 ][negative accuracy: 0.772 ]\n",
      "testcase: 321 [l3: 0.1217][l2: 0.8774][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.78  ][negative accuracy: 0.784 ]\n",
      "testcase: 328 [l3: 0.0979][l2: 0.9011][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.78  ][negative accuracy: 0.784 ]\n",
      "testcase: 379 [l3: 0.1379][l2: 0.8611][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.78  ][negative accuracy: 0.784 ]\n",
      "testcase: 383 [l3: 0.2636][l2: 0.7353][l1: 0.0011][e: 0.001 ] ==> [positive accuracy: 0.778 ][negative accuracy: 0.786 ]\n",
      "testcase: 395 [l3: 0.1358][l2: 0.8633][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.78  ][negative accuracy: 0.784 ]\n",
      "testcase: 400 [l3: 0.239 ][l2: 0.7601][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.78  ][negative accuracy: 0.784 ]\n",
      "testcase: 449 [l3: 0.1375][l2: 0.8616][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.78  ][negative accuracy: 0.784 ]\n",
      "testcase: 474 [l3: 0.281 ][l2: 0.7175][l1: 0.0014][e: 0.001 ] ==> [positive accuracy: 0.778 ][negative accuracy: 0.786 ]\n",
      "testcase: 484 [l3: 0.1601][l2: 0.8387][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.778 ][negative accuracy: 0.786 ]\n",
      "testcase: 0   [l3: 0.1573][l2: 0.8411][l1: 0.0015][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.786 ]\n",
      "testcase: 2   [l3: 0.3984][l2: 0.6005][l1: 0.0011][e: 0.001 ] ==> [positive accuracy: 0.778 ][negative accuracy: 0.784 ]\n",
      "testcase: 15  [l3: 0.1532][l2: 0.8452][l1: 0.0016][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.786 ]\n",
      "testcase: 29  [l3: 0.1325][l2: 0.8663][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.778 ][negative accuracy: 0.784 ]\n",
      "testcase: 36  [l3: 0.2917][l2: 0.7068][l1: 0.0015][e: 0.001 ] ==> [positive accuracy: 0.778 ][negative accuracy: 0.784 ]\n",
      "testcase: 52  [l3: 0.2958][l2: 0.7027][l1: 0.0015][e: 0.001 ] ==> [positive accuracy: 0.778 ][negative accuracy: 0.784 ]\n",
      "testcase: 54  [l3: 0.2939][l2: 0.7043][l1: 0.0017][e: 0.001 ] ==> [positive accuracy: 0.778 ][negative accuracy: 0.784 ]\n",
      "testcase: 72  [l3: 0.0617][l2: 0.937 ][l1: 0.0013][e: 0.001 ] ==> [positive accuracy: 0.782 ][negative accuracy: 0.78  ]\n",
      "testcase: 83  [l3: 0.3982][l2: 0.6007][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.778 ][negative accuracy: 0.784 ]\n",
      "testcase: 105 [l3: 0.3973][l2: 0.6016][l1: 0.0011][e: 0.001 ] ==> [positive accuracy: 0.778 ][negative accuracy: 0.784 ]\n",
      "testcase: 137 [l3: 0.1638][l2: 0.835 ][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.786 ]\n",
      "testcase: 165 [l3: 0.3007][l2: 0.698 ][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.778 ][negative accuracy: 0.784 ]\n",
      "testcase: 194 [l3: 0.1445][l2: 0.8545][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.778 ][negative accuracy: 0.784 ]\n",
      "testcase: 220 [l3: 0.0596][l2: 0.9392][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.782 ][negative accuracy: 0.78  ]\n",
      "testcase: 243 [l3: 0.4079][l2: 0.5913][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.786 ]\n",
      "testcase: 255 [l3: 0.2937][l2: 0.7048][l1: 0.0015][e: 0.001 ] ==> [positive accuracy: 0.778 ][negative accuracy: 0.784 ]\n",
      "testcase: 299 [l3: 0.2983][l2: 0.7005][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.778 ][negative accuracy: 0.784 ]\n",
      "testcase: 326 [l3: 0.1456][l2: 0.8468][l1: 0.0076][e: 0.001 ] ==> [positive accuracy: 0.778 ][negative accuracy: 0.784 ]\n",
      "testcase: 382 [l3: 0.028 ][l2: 0.9707][l1: 0.0013][e: 0.001 ] ==> [positive accuracy: 0.788 ][negative accuracy: 0.774 ]\n",
      "testcase: 396 [l3: 0.2975][l2: 0.7015][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.778 ][negative accuracy: 0.784 ]\n",
      "testcase: 415 [l3: 0.3971][l2: 0.6023][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.778 ][negative accuracy: 0.784 ]\n",
      "testcase: 419 [l3: 0.132 ][l2: 0.8668][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.778 ][negative accuracy: 0.784 ]\n",
      "testcase: 423 [l3: 0.3965][l2: 0.6025][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.778 ][negative accuracy: 0.784 ]\n",
      "testcase: 431 [l3: 0.0125][l2: 0.9864][l1: 0.0011][e: 0.001 ] ==> [positive accuracy: 0.79  ][negative accuracy: 0.772 ]\n",
      "testcase: 435 [l3: 0.1316][l2: 0.8666][l1: 0.0018][e: 0.001 ] ==> [positive accuracy: 0.78  ][negative accuracy: 0.782 ]\n",
      "testcase: 6   [l3: 0.411 ][l2: 0.5883][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.774 ][negative accuracy: 0.786 ]\n",
      "testcase: 56  [l3: 0.3442][l2: 0.6552][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.784 ]\n",
      "testcase: 64  [l3: 0.3922][l2: 0.6071][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.784 ]\n",
      "testcase: 68  [l3: 0.4127][l2: 0.5866][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.774 ][negative accuracy: 0.786 ]\n",
      "testcase: 82  [l3: 0.2837][l2: 0.711 ][l1: 0.0053][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.784 ]\n",
      "testcase: 94  [l3: 0.3823][l2: 0.617 ][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.784 ]\n",
      "testcase: 98  [l3: 0.4051][l2: 0.5937][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.784 ]\n",
      "testcase: 101 [l3: 0.3498][l2: 0.6483][l1: 0.0019][e: 0.001 ] ==> [positive accuracy: 0.778 ][negative accuracy: 0.782 ]\n",
      "testcase: 117 [l3: 0.4061][l2: 0.5931][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.784 ]\n",
      "testcase: 120 [l3: 0.1398][l2: 0.8582][l1: 0.0019][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.784 ]\n",
      "testcase: 127 [l3: 0.148 ][l2: 0.8498][l1: 0.0022][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.784 ]\n",
      "testcase: 149 [l3: 0.3813][l2: 0.618 ][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.784 ]\n",
      "testcase: 168 [l3: 0.3539][l2: 0.645 ][l1: 0.0011][e: 0.001 ] ==> [positive accuracy: 0.778 ][negative accuracy: 0.782 ]\n",
      "testcase: 178 [l3: 0.405 ][l2: 0.5934][l1: 0.0016][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.784 ]\n",
      "testcase: 184 [l3: 0.3761][l2: 0.6233][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.784 ]\n",
      "testcase: 189 [l3: 0.392 ][l2: 0.6072][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.784 ]\n",
      "testcase: 190 [l3: 0.3378][l2: 0.6606][l1: 0.0016][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.784 ]\n",
      "testcase: 192 [l3: 0.3572][l2: 0.6422][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.778 ][negative accuracy: 0.782 ]\n",
      "testcase: 193 [l3: 0.011 ][l2: 0.9869][l1: 0.0021][e: 0.001 ] ==> [positive accuracy: 0.788 ][negative accuracy: 0.772 ]\n",
      "testcase: 197 [l3: 0.4036][l2: 0.5956][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.784 ]\n",
      "testcase: 211 [l3: 0.3566][l2: 0.6422][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.778 ][negative accuracy: 0.782 ]\n",
      "testcase: 236 [l3: 0.0202][l2: 0.9759][l1: 0.0039][e: 0.001 ] ==> [positive accuracy: 0.786 ][negative accuracy: 0.774 ]\n",
      "testcase: 259 [l3: 0.405 ][l2: 0.5941][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.784 ]\n",
      "testcase: 261 [l3: 0.3755][l2: 0.6231][l1: 0.0014][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.784 ]\n",
      "testcase: 319 [l3: 0.3345][l2: 0.6637][l1: 0.0018][e: 0.001 ] ==> [positive accuracy: 0.774 ][negative accuracy: 0.786 ]\n",
      "testcase: 335 [l3: 0.4066][l2: 0.5926][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.784 ]\n",
      "testcase: 338 [l3: 0.4023][l2: 0.5971][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.784 ]\n",
      "testcase: 347 [l3: 0.3784][l2: 0.6208][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.784 ]\n",
      "testcase: 375 [l3: 0.1426][l2: 0.8556][l1: 0.0018][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.784 ]\n",
      "testcase: 385 [l3: 0.3813][l2: 0.618 ][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.784 ]\n",
      "testcase: 406 [l3: 0.4011][l2: 0.5979][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.784 ]\n",
      "testcase: 413 [l3: 0.3429][l2: 0.6563][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.784 ]\n",
      "testcase: 432 [l3: 0.3919][l2: 0.6071][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.784 ]\n",
      "testcase: 438 [l3: 0.3902][l2: 0.6091][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.784 ]\n",
      "testcase: 441 [l3: 0.3803][l2: 0.619 ][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.784 ]\n",
      "testcase: 477 [l3: 0.3789][l2: 0.6201][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.784 ]\n",
      "testcase: 488 [l3: 0.146 ][l2: 0.8521][l1: 0.0019][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.784 ]\n",
      "testcase: 491 [l3: 0.4058][l2: 0.5925][l1: 0.0017][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.784 ]\n",
      "testcase: 30  [l3: 0.3846][l2: 0.6125][l1: 0.0028][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.782 ]\n",
      "testcase: 48  [l3: 0.3641][l2: 0.6349][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.782 ]\n",
      "testcase: 49  [l3: 0.366 ][l2: 0.6332][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.782 ]\n",
      "testcase: 219 [l3: 0.371 ][l2: 0.6282][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.774 ][negative accuracy: 0.784 ]\n",
      "testcase: 240 [l3: 0.3873][l2: 0.6117][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.782 ]\n",
      "testcase: 325 [l3: 0.3774][l2: 0.621 ][l1: 0.0016][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.782 ]\n",
      "testcase: 329 [l3: 0.3715][l2: 0.6279][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.774 ][negative accuracy: 0.784 ]\n",
      "testcase: 439 [l3: 0.1502][l2: 0.8487][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.774 ][negative accuracy: 0.784 ]\n",
      "testcase: 461 [l3: 0.4123][l2: 0.5865][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.774 ][negative accuracy: 0.784 ]\n",
      "testcase: 493 [l3: 0.3605][l2: 0.638 ][l1: 0.0015][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.782 ]\n",
      "testcase: 55  [l3: 0.3652][l2: 0.6336][l1: 0.0011][e: 0.001 ] ==> [positive accuracy: 0.774 ][negative accuracy: 0.782 ]\n",
      "testcase: 138 [l3: 0.3636][l2: 0.6348][l1: 0.0017][e: 0.001 ] ==> [positive accuracy: 0.774 ][negative accuracy: 0.782 ]\n",
      "testcase: 144 [l3: 0.349 ][l2: 0.6481][l1: 0.0029][e: 0.001 ] ==> [positive accuracy: 0.774 ][negative accuracy: 0.782 ]\n",
      "testcase: 191 [l3: 0.3358][l2: 0.6617][l1: 0.0025][e: 0.001 ] ==> [positive accuracy: 0.774 ][negative accuracy: 0.782 ]\n",
      "testcase: 229 [l3: 0.0051][l2: 0.993 ][l1: 0.0019][e: 0.001 ] ==> [positive accuracy: 0.788 ][negative accuracy: 0.768 ]\n",
      "testcase: 263 [l3: 0.0877][l2: 0.9084][l1: 0.0039][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.78  ]\n",
      "testcase: 342 [l3: 0.3111][l2: 0.6823][l1: 0.0066][e: 0.001 ] ==> [positive accuracy: 0.774 ][negative accuracy: 0.782 ]\n",
      "testcase: 371 [l3: 0.005 ][l2: 0.9933][l1: 0.0016][e: 0.001 ] ==> [positive accuracy: 0.788 ][negative accuracy: 0.768 ]\n",
      "testcase: 445 [l3: 0.3396][l2: 0.6574][l1: 0.0029][e: 0.001 ] ==> [positive accuracy: 0.776 ][negative accuracy: 0.78  ]\n",
      "testcase: 19  [l3: 0.3093][l2: 0.6852][l1: 0.0055][e: 0.001 ] ==> [positive accuracy: 0.772 ][negative accuracy: 0.782 ]\n",
      "testcase: 104 [l3: 0.4187][l2: 0.5806][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.77  ][negative accuracy: 0.784 ]\n",
      "testcase: 159 [l3: 0.3619][l2: 0.6356][l1: 0.0025][e: 0.001 ] ==> [positive accuracy: 0.772 ][negative accuracy: 0.782 ]\n",
      "testcase: 303 [l3: 0.4182][l2: 0.5812][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.77  ][negative accuracy: 0.784 ]\n",
      "testcase: 374 [l3: 0.3221][l2: 0.6746][l1: 0.0033][e: 0.001 ] ==> [positive accuracy: 0.774 ][negative accuracy: 0.78  ]\n",
      "testcase: 61  [l3: 0.3287][l2: 0.6661][l1: 0.0053][e: 0.001 ] ==> [positive accuracy: 0.774 ][negative accuracy: 0.778 ]\n",
      "testcase: 136 [l3: 0.4189][l2: 0.5799][l1: 0.0011][e: 0.001 ] ==> [positive accuracy: 0.77  ][negative accuracy: 0.782 ]\n",
      "testcase: 147 [l3: 0.4198][l2: 0.5796][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.768 ][negative accuracy: 0.784 ]\n",
      "testcase: 235 [l3: 0.0004][l2: 0.9985][l1: 0.0011][e: 0.001 ] ==> [positive accuracy: 0.784 ][negative accuracy: 0.768 ]\n",
      "testcase: 216 [l3: 0.4302][l2: 0.5691][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.768 ][negative accuracy: 0.782 ]\n",
      "testcase: 234 [l3: 0.4258][l2: 0.5735][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.768 ][negative accuracy: 0.782 ]\n",
      "testcase: 258 [l3: 0.4258][l2: 0.5733][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.768 ][negative accuracy: 0.782 ]\n",
      "testcase: 394 [l3: 0.4284][l2: 0.5709][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.768 ][negative accuracy: 0.782 ]\n",
      "testcase: 425 [l3: 0.4216][l2: 0.5778][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.768 ][negative accuracy: 0.782 ]\n",
      "testcase: 470 [l3: 0.4243][l2: 0.5751][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.768 ][negative accuracy: 0.782 ]\n",
      "testcase: 44  [l3: 0.4529][l2: 0.5465][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.766 ][negative accuracy: 0.782 ]\n",
      "testcase: 58  [l3: 0.4482][l2: 0.5511][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.766 ][negative accuracy: 0.782 ]\n",
      "testcase: 97  [l3: 0.4521][l2: 0.5468][l1: 0.0011][e: 0.001 ] ==> [positive accuracy: 0.766 ][negative accuracy: 0.782 ]\n",
      "testcase: 99  [l3: 0.4483][l2: 0.5503][l1: 0.0015][e: 0.001 ] ==> [positive accuracy: 0.766 ][negative accuracy: 0.782 ]\n",
      "testcase: 368 [l3: 0.4512][l2: 0.5482][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.766 ][negative accuracy: 0.782 ]\n",
      "testcase: 405 [l3: 0.4314][l2: 0.5677][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.766 ][negative accuracy: 0.782 ]\n",
      "testcase: 456 [l3: 0.4366][l2: 0.5629][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.766 ][negative accuracy: 0.782 ]\n",
      "testcase: 480 [l3: 0.4494][l2: 0.5496][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.766 ][negative accuracy: 0.782 ]\n",
      "testcase: 81  [l3: 0.4413][l2: 0.558 ][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.764 ][negative accuracy: 0.782 ]\n",
      "testcase: 110 [l3: 0.433 ][l2: 0.564 ][l1: 0.0029][e: 0.001 ] ==> [positive accuracy: 0.764 ][negative accuracy: 0.782 ]\n",
      "testcase: 156 [l3: 0.4446][l2: 0.5548][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.764 ][negative accuracy: 0.782 ]\n",
      "testcase: 214 [l3: 0.4411][l2: 0.5581][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.764 ][negative accuracy: 0.782 ]\n",
      "testcase: 224 [l3: 0.4397][l2: 0.5597][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.764 ][negative accuracy: 0.782 ]\n",
      "testcase: 238 [l3: 0.4601][l2: 0.5393][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.762 ][negative accuracy: 0.784 ]\n",
      "testcase: 285 [l3: 0.4406][l2: 0.5589][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.764 ][negative accuracy: 0.782 ]\n",
      "testcase: 289 [l3: 0.4473][l2: 0.5519][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.766 ][negative accuracy: 0.78  ]\n",
      "testcase: 291 [l3: 0.4409][l2: 0.5584][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.764 ][negative accuracy: 0.782 ]\n",
      "testcase: 312 [l3: 0.4527][l2: 0.5462][l1: 0.0011][e: 0.001 ] ==> [positive accuracy: 0.764 ][negative accuracy: 0.782 ]\n",
      "testcase: 494 [l3: 0.4348][l2: 0.5632][l1: 0.002 ][e: 0.001 ] ==> [positive accuracy: 0.764 ][negative accuracy: 0.782 ]\n",
      "testcase: 17  [l3: 0.4465][l2: 0.5529][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.764 ][negative accuracy: 0.78  ]\n",
      "testcase: 32  [l3: 0.4713][l2: 0.5272][l1: 0.0015][e: 0.001 ] ==> [positive accuracy: 0.756 ][negative accuracy: 0.788 ]\n",
      "testcase: 45  [l3: 0.4733][l2: 0.5254][l1: 0.0013][e: 0.001 ] ==> [positive accuracy: 0.756 ][negative accuracy: 0.788 ]\n",
      "testcase: 171 [l3: 0.4613][l2: 0.5378][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.76  ][negative accuracy: 0.784 ]\n",
      "testcase: 181 [l3: 0.4739][l2: 0.5246][l1: 0.0016][e: 0.001 ] ==> [positive accuracy: 0.756 ][negative accuracy: 0.788 ]\n",
      "testcase: 246 [l3: 0.2149][l2: 0.7639][l1: 0.0212][e: 0.001 ] ==> [positive accuracy: 0.768 ][negative accuracy: 0.776 ]\n",
      "testcase: 301 [l3: 0.4499][l2: 0.5482][l1: 0.0018][e: 0.001 ] ==> [positive accuracy: 0.762 ][negative accuracy: 0.782 ]\n",
      "testcase: 352 [l3: 0.4555][l2: 0.5437][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.762 ][negative accuracy: 0.782 ]\n",
      "testcase: 487 [l3: 0.449 ][l2: 0.5487][l1: 0.0023][e: 0.001 ] ==> [positive accuracy: 0.762 ][negative accuracy: 0.782 ]\n",
      "testcase: 41  [l3: 0.4789][l2: 0.5205][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.754 ][negative accuracy: 0.788 ]\n",
      "testcase: 63  [l3: 0.4782][l2: 0.5211][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.754 ][negative accuracy: 0.788 ]\n",
      "testcase: 70  [l3: 0.4912][l2: 0.5083][l1: 0.0005][e: 0.001 ] ==> [positive accuracy: 0.754 ][negative accuracy: 0.788 ]\n",
      "testcase: 80  [l3: 0.4741][l2: 0.5253][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.756 ][negative accuracy: 0.786 ]\n",
      "testcase: 84  [l3: 0.4909][l2: 0.5086][l1: 0.0005][e: 0.001 ] ==> [positive accuracy: 0.754 ][negative accuracy: 0.788 ]\n",
      "testcase: 134 [l3: 0.473 ][l2: 0.5263][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.756 ][negative accuracy: 0.786 ]\n",
      "testcase: 313 [l3: 0.4752][l2: 0.5241][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.756 ][negative accuracy: 0.786 ]\n",
      "testcase: 454 [l3: 0.4801][l2: 0.5193][l1: 0.0005][e: 0.001 ] ==> [positive accuracy: 0.754 ][negative accuracy: 0.788 ]\n",
      "testcase: 1   [l3: 0.4921][l2: 0.5073][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.788 ]\n",
      "testcase: 23  [l3: 0.6133][l2: 0.3853][l1: 0.0013][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.79  ]\n",
      "testcase: 28  [l3: 0.4616][l2: 0.5368][l1: 0.0016][e: 0.001 ] ==> [positive accuracy: 0.756 ][negative accuracy: 0.784 ]\n",
      "testcase: 46  [l3: 0.4911][l2: 0.5083][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.788 ]\n",
      "testcase: 88  [l3: 0.4936][l2: 0.5058][l1: 0.0005][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.788 ]\n",
      "testcase: 126 [l3: 0.6112][l2: 0.3873][l1: 0.0015][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.79  ]\n",
      "testcase: 131 [l3: 0.4844][l2: 0.514 ][l1: 0.0016][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.788 ]\n",
      "testcase: 222 [l3: 0.4879][l2: 0.5116][l1: 0.0005][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.788 ]\n",
      "testcase: 237 [l3: 0.4828][l2: 0.5161][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.788 ]\n",
      "testcase: 249 [l3: 0.485 ][l2: 0.5144][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.788 ]\n",
      "testcase: 286 [l3: 0.486 ][l2: 0.5131][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.788 ]\n",
      "testcase: 302 [l3: 0.6178][l2: 0.3815][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.79  ]\n",
      "testcase: 341 [l3: 0.4663][l2: 0.5332][l1: 0.0005][e: 0.001 ] ==> [positive accuracy: 0.756 ][negative accuracy: 0.784 ]\n",
      "testcase: 344 [l3: 0.6157][l2: 0.3836][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.79  ]\n",
      "testcase: 391 [l3: 0.4687][l2: 0.5307][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.756 ][negative accuracy: 0.784 ]\n",
      "testcase: 409 [l3: 0.4945][l2: 0.505 ][l1: 0.0005][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.788 ]\n",
      "testcase: 424 [l3: 0.4851][l2: 0.5138][l1: 0.0011][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.788 ]\n",
      "testcase: 13  [l3: 0.5136][l2: 0.4858][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.786 ]\n",
      "testcase: 31  [l3: 0.501 ][l2: 0.4968][l1: 0.0022][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.786 ]\n",
      "testcase: 65  [l3: 0.4998][l2: 0.4995][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.786 ]\n",
      "testcase: 71  [l3: 0.4932][l2: 0.5058][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.786 ]\n",
      "testcase: 79  [l3: 0.4964][l2: 0.5025][l1: 0.0011][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.786 ]\n",
      "testcase: 112 [l3: 0.4988][l2: 0.4993][l1: 0.0019][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.786 ]\n",
      "testcase: 128 [l3: 0.5188][l2: 0.4798][l1: 0.0014][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.786 ]\n",
      "testcase: 162 [l3: 0.4894][l2: 0.5096][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.788 ]\n",
      "testcase: 166 [l3: 0.5017][l2: 0.4977][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.786 ]\n",
      "testcase: 177 [l3: 0.5008][l2: 0.4985][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.786 ]\n",
      "testcase: 186 [l3: 0.4997][l2: 0.4991][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.786 ]\n",
      "testcase: 199 [l3: 0.5038][l2: 0.4957][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.786 ]\n",
      "testcase: 228 [l3: 0.514 ][l2: 0.4854][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.786 ]\n",
      "testcase: 231 [l3: 0.5208][l2: 0.4784][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.786 ]\n",
      "testcase: 232 [l3: 0.722 ][l2: 0.2772][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.756 ][negative accuracy: 0.782 ]\n",
      "testcase: 244 [l3: 0.494 ][l2: 0.5044][l1: 0.0015][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.786 ]\n",
      "testcase: 252 [l3: 0.6136][l2: 0.3845][l1: 0.0019][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.79  ]\n",
      "testcase: 266 [l3: 0.5165][l2: 0.4822][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.786 ]\n",
      "testcase: 273 [l3: 0.5151][l2: 0.4837][l1: 0.0013][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.786 ]\n",
      "testcase: 278 [l3: 0.5195][l2: 0.4795][l1: 0.0011][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.786 ]\n",
      "testcase: 283 [l3: 0.5143][l2: 0.4851][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.786 ]\n",
      "testcase: 304 [l3: 0.5002][l2: 0.4989][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.786 ]\n",
      "testcase: 306 [l3: 0.5169][l2: 0.4826][l1: 0.0005][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.786 ]\n",
      "testcase: 354 [l3: 0.4829][l2: 0.5137][l1: 0.0034][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.786 ]\n",
      "testcase: 365 [l3: 0.6187][l2: 0.3803][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.79  ]\n",
      "testcase: 367 [l3: 0.5132][l2: 0.4856][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.786 ]\n",
      "testcase: 398 [l3: 0.6106][l2: 0.3888][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.79  ]\n",
      "testcase: 407 [l3: 0.5196][l2: 0.4797][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.786 ]\n",
      "testcase: 411 [l3: 0.5031][l2: 0.4962][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.786 ]\n",
      "testcase: 434 [l3: 0.7219][l2: 0.2773][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.756 ][negative accuracy: 0.782 ]\n",
      "testcase: 442 [l3: 0.5162][l2: 0.4818][l1: 0.0021][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.786 ]\n",
      "testcase: 444 [l3: 0.4954][l2: 0.5027][l1: 0.0019][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.786 ]\n",
      "testcase: 446 [l3: 0.5231][l2: 0.4762][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.786 ]\n",
      "testcase: 457 [l3: 0.5019][l2: 0.4976][l1: 0.0005][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.786 ]\n",
      "testcase: 459 [l3: 0.5003][l2: 0.4976][l1: 0.0021][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.786 ]\n",
      "testcase: 464 [l3: 0.5155][l2: 0.4839][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.786 ]\n",
      "testcase: 465 [l3: 0.7248][l2: 0.2744][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.756 ][negative accuracy: 0.782 ]\n",
      "testcase: 471 [l3: 0.5208][l2: 0.478 ][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.786 ]\n",
      "testcase: 38  [l3: 0.7848][l2: 0.2141][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.788 ]\n",
      "testcase: 50  [l3: 0.7207][l2: 0.2785][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.754 ][negative accuracy: 0.782 ]\n",
      "testcase: 60  [l3: 0.6291][l2: 0.3699][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.786 ]\n",
      "testcase: 108 [l3: 0.6269][l2: 0.3725][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.786 ]\n",
      "testcase: 123 [l3: 0.6072][l2: 0.3919][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.788 ]\n",
      "testcase: 141 [l3: 0.5035][l2: 0.4945][l1: 0.002 ][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.784 ]\n",
      "testcase: 206 [l3: 0.7275][l2: 0.2709][l1: 0.0016][e: 0.001 ] ==> [positive accuracy: 0.754 ][negative accuracy: 0.782 ]\n",
      "testcase: 209 [l3: 0.5087][l2: 0.4908][l1: 0.0005][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.784 ]\n",
      "testcase: 225 [l3: 0.783 ][l2: 0.2158][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.788 ]\n",
      "testcase: 239 [l3: 0.5269][l2: 0.4725][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.786 ]\n",
      "testcase: 253 [l3: 0.8145][l2: 0.1845][l1: 0.0011][e: 0.001 ] ==> [positive accuracy: 0.746 ][negative accuracy: 0.79  ]\n",
      "testcase: 260 [l3: 0.7283][l2: 0.2707][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.754 ][negative accuracy: 0.782 ]\n",
      "testcase: 290 [l3: 0.7942][l2: 0.2039][l1: 0.002 ][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.788 ]\n",
      "testcase: 294 [l3: 0.6086][l2: 0.3907][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.788 ]\n",
      "testcase: 297 [l3: 0.505 ][l2: 0.4944][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.784 ]\n",
      "testcase: 334 [l3: 0.5074][l2: 0.4915][l1: 0.0011][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.784 ]\n",
      "testcase: 355 [l3: 0.508 ][l2: 0.4912][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.784 ]\n",
      "testcase: 359 [l3: 0.608 ][l2: 0.3909][l1: 0.0011][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.788 ]\n",
      "testcase: 360 [l3: 0.7825][l2: 0.2167][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.788 ]\n",
      "testcase: 362 [l3: 0.5262][l2: 0.4731][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.786 ]\n",
      "testcase: 363 [l3: 0.7806][l2: 0.2183][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.786 ]\n",
      "testcase: 404 [l3: 0.628 ][l2: 0.3711][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.786 ]\n",
      "testcase: 408 [l3: 0.505 ][l2: 0.4943][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.784 ]\n",
      "testcase: 417 [l3: 0.8125][l2: 0.1867][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.746 ][negative accuracy: 0.79  ]\n",
      "testcase: 427 [l3: 0.6244][l2: 0.3742][l1: 0.0014][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.786 ]\n",
      "testcase: 437 [l3: 0.5051][l2: 0.4944][l1: 0.0005][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.784 ]\n",
      "testcase: 475 [l3: 0.6261][l2: 0.3728][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.786 ]\n",
      "testcase: 22  [l3: 0.7779][l2: 0.2212][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.784 ]\n",
      "testcase: 37  [l3: 0.5415][l2: 0.4579][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.746 ][negative accuracy: 0.788 ]\n",
      "testcase: 39  [l3: 0.513 ][l2: 0.4831][l1: 0.0039][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.784 ]\n",
      "testcase: 42  [l3: 0.7941][l2: 0.2049][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.786 ]\n",
      "testcase: 51  [l3: 0.8251][l2: 0.1741][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.746 ][negative accuracy: 0.788 ]\n",
      "testcase: 74  [l3: 0.6295][l2: 0.3697][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.784 ]\n",
      "testcase: 78  [l3: 0.8206][l2: 0.1785][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.746 ][negative accuracy: 0.788 ]\n",
      "testcase: 90  [l3: 0.6357][l2: 0.3631][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.784 ]\n",
      "testcase: 130 [l3: 0.5328][l2: 0.4663][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.786 ]\n",
      "testcase: 145 [l3: 0.7572][l2: 0.2351][l1: 0.0077][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.784 ]\n",
      "testcase: 157 [l3: 0.7994][l2: 0.1996][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.746 ][negative accuracy: 0.788 ]\n",
      "testcase: 161 [l3: 0.6362][l2: 0.3626][l1: 0.0013][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.784 ]\n",
      "testcase: 172 [l3: 0.5381][l2: 0.4599][l1: 0.0021][e: 0.001 ] ==> [positive accuracy: 0.746 ][negative accuracy: 0.788 ]\n",
      "testcase: 176 [l3: 0.5336][l2: 0.4656][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.786 ]\n",
      "testcase: 198 [l3: 0.643 ][l2: 0.3544][l1: 0.0026][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.786 ]\n",
      "testcase: 212 [l3: 0.7996][l2: 0.1972][l1: 0.0032][e: 0.001 ] ==> [positive accuracy: 0.746 ][negative accuracy: 0.788 ]\n",
      "testcase: 215 [l3: 0.5335][l2: 0.4659][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.786 ]\n",
      "testcase: 221 [l3: 0.7307][l2: 0.268 ][l1: 0.0013][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.782 ]\n",
      "testcase: 254 [l3: 0.8036][l2: 0.1955][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.746 ][negative accuracy: 0.788 ]\n",
      "testcase: 270 [l3: 0.6414][l2: 0.3571][l1: 0.0015][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.786 ]\n",
      "testcase: 276 [l3: 0.5297][l2: 0.4695][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.786 ]\n",
      "testcase: 309 [l3: 0.8254][l2: 0.1737][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.746 ][negative accuracy: 0.788 ]\n",
      "testcase: 310 [l3: 0.5432][l2: 0.456 ][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.746 ][negative accuracy: 0.788 ]\n",
      "testcase: 314 [l3: 0.7902][l2: 0.2089][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.786 ]\n",
      "testcase: 317 [l3: 0.6457][l2: 0.3526][l1: 0.0017][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.786 ]\n",
      "testcase: 323 [l3: 0.8006][l2: 0.1982][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.746 ][negative accuracy: 0.788 ]\n",
      "testcase: 324 [l3: 0.8184][l2: 0.1808][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.746 ][negative accuracy: 0.788 ]\n",
      "testcase: 348 [l3: 0.803 ][l2: 0.1959][l1: 0.0011][e: 0.001 ] ==> [positive accuracy: 0.746 ][negative accuracy: 0.788 ]\n",
      "testcase: 356 [l3: 0.8102][l2: 0.1886][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.746 ][negative accuracy: 0.788 ]\n",
      "testcase: 364 [l3: 0.8237][l2: 0.1747][l1: 0.0016][e: 0.001 ] ==> [positive accuracy: 0.746 ][negative accuracy: 0.788 ]\n",
      "testcase: 369 [l3: 0.6485][l2: 0.3476][l1: 0.0039][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.784 ]\n",
      "testcase: 428 [l3: 0.6302][l2: 0.3691][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.784 ]\n",
      "testcase: 455 [l3: 0.6362][l2: 0.3623][l1: 0.0015][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.784 ]\n",
      "testcase: 463 [l3: 0.6024][l2: 0.3951][l1: 0.0025][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.786 ]\n",
      "testcase: 9   [l3: 0.6755][l2: 0.3232][l1: 0.0013][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.782 ]\n",
      "testcase: 16  [l3: 0.7357][l2: 0.2627][l1: 0.0016][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.782 ]\n",
      "testcase: 24  [l3: 0.5457][l2: 0.4534][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.746 ][negative accuracy: 0.786 ]\n",
      "testcase: 43  [l3: 0.8304][l2: 0.1687][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.744 ][negative accuracy: 0.788 ]\n",
      "testcase: 57  [l3: 0.5469][l2: 0.4522][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.746 ][negative accuracy: 0.786 ]\n",
      "testcase: 67  [l3: 0.5842][l2: 0.4149][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.744 ][negative accuracy: 0.788 ]\n",
      "testcase: 76  [l3: 0.7563][l2: 0.2427][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.782 ]\n",
      "testcase: 85  [l3: 0.7475][l2: 0.2517][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.782 ]\n",
      "testcase: 86  [l3: 0.6743][l2: 0.3247][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.782 ]\n",
      "testcase: 91  [l3: 0.7968][l2: 0.2024][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.746 ][negative accuracy: 0.786 ]\n",
      "testcase: 95  [l3: 0.6406][l2: 0.3585][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.784 ]\n",
      "testcase: 109 [l3: 0.5859][l2: 0.4132][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.744 ][negative accuracy: 0.788 ]\n",
      "testcase: 116 [l3: 0.6771][l2: 0.3221][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.782 ]\n",
      "testcase: 119 [l3: 0.7564][l2: 0.2428][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.782 ]\n",
      "testcase: 124 [l3: 0.5511][l2: 0.4483][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.744 ][negative accuracy: 0.788 ]\n",
      "testcase: 125 [l3: 0.8333][l2: 0.1657][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.744 ][negative accuracy: 0.788 ]\n",
      "testcase: 133 [l3: 0.6461][l2: 0.3533][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.784 ]\n",
      "testcase: 135 [l3: 0.7202][l2: 0.2772][l1: 0.0025][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.78  ]\n",
      "testcase: 142 [l3: 0.7027][l2: 0.2961][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.78  ]\n",
      "testcase: 148 [l3: 0.5584][l2: 0.4406][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.744 ][negative accuracy: 0.788 ]\n",
      "testcase: 163 [l3: 0.7365][l2: 0.2627][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.782 ]\n",
      "testcase: 164 [l3: 0.549 ][l2: 0.4499][l1: 0.0011][e: 0.001 ] ==> [positive accuracy: 0.746 ][negative accuracy: 0.786 ]\n",
      "testcase: 167 [l3: 0.7076][l2: 0.2915][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.78  ]\n",
      "testcase: 169 [l3: 0.8278][l2: 0.1713][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.744 ][negative accuracy: 0.788 ]\n",
      "testcase: 179 [l3: 0.7712][l2: 0.2277][l1: 0.0011][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.784 ]\n",
      "testcase: 188 [l3: 0.5825][l2: 0.4164][l1: 0.0011][e: 0.001 ] ==> [positive accuracy: 0.744 ][negative accuracy: 0.788 ]\n",
      "testcase: 205 [l3: 0.5842][l2: 0.4152][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.744 ][negative accuracy: 0.788 ]\n",
      "testcase: 207 [l3: 0.5511][l2: 0.4475][l1: 0.0014][e: 0.001 ] ==> [positive accuracy: 0.744 ][negative accuracy: 0.788 ]\n",
      "testcase: 213 [l3: 0.5468][l2: 0.4524][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.746 ][negative accuracy: 0.786 ]\n",
      "testcase: 241 [l3: 0.5585][l2: 0.4407][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.744 ][negative accuracy: 0.788 ]\n",
      "testcase: 248 [l3: 0.6756][l2: 0.3232][l1: 0.0013][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.782 ]\n",
      "testcase: 251 [l3: 0.5523][l2: 0.447 ][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.744 ][negative accuracy: 0.788 ]\n",
      "testcase: 272 [l3: 0.5862][l2: 0.4126][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.744 ][negative accuracy: 0.788 ]\n",
      "testcase: 277 [l3: 0.6724][l2: 0.3269][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.782 ]\n",
      "testcase: 288 [l3: 0.7029][l2: 0.2963][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.78  ]\n",
      "testcase: 292 [l3: 0.5899][l2: 0.4094][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.744 ][negative accuracy: 0.788 ]\n",
      "testcase: 300 [l3: 0.7071][l2: 0.2921][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.78  ]\n",
      "testcase: 308 [l3: 0.6495][l2: 0.3497][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.784 ]\n",
      "testcase: 320 [l3: 0.5582][l2: 0.4411][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.744 ][negative accuracy: 0.788 ]\n",
      "testcase: 322 [l3: 0.711 ][l2: 0.2878][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.78  ]\n",
      "testcase: 327 [l3: 0.5446][l2: 0.4549][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.746 ][negative accuracy: 0.786 ]\n",
      "testcase: 332 [l3: 0.6459][l2: 0.3533][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.784 ]\n",
      "testcase: 339 [l3: 0.6495][l2: 0.3498][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.784 ]\n",
      "testcase: 373 [l3: 0.5376][l2: 0.4613][l1: 0.0011][e: 0.001 ] ==> [positive accuracy: 0.746 ][negative accuracy: 0.786 ]\n",
      "testcase: 384 [l3: 0.7609][l2: 0.2378][l1: 0.0014][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.782 ]\n",
      "testcase: 393 [l3: 0.7406][l2: 0.2576][l1: 0.0017][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.782 ]\n",
      "testcase: 402 [l3: 0.6675][l2: 0.3295][l1: 0.0029][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.782 ]\n",
      "testcase: 440 [l3: 0.8268][l2: 0.1724][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.744 ][negative accuracy: 0.788 ]\n",
      "testcase: 447 [l3: 0.8287][l2: 0.1703][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.744 ][negative accuracy: 0.788 ]\n",
      "testcase: 482 [l3: 0.5574][l2: 0.4418][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.744 ][negative accuracy: 0.788 ]\n",
      "testcase: 485 [l3: 0.6001][l2: 0.3988][l1: 0.0011][e: 0.001 ] ==> [positive accuracy: 0.746 ][negative accuracy: 0.786 ]\n",
      "testcase: 497 [l3: 0.5863][l2: 0.413 ][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.744 ][negative accuracy: 0.788 ]\n",
      "testcase: 18  [l3: 0.6831][l2: 0.3161][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.78  ]\n",
      "testcase: 25  [l3: 0.6956][l2: 0.3032][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.778 ]\n",
      "testcase: 40  [l3: 0.6908][l2: 0.3084][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.78  ]\n",
      "testcase: 62  [l3: 0.6569][l2: 0.3412][l1: 0.0019][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.782 ]\n",
      "testcase: 69  [l3: 0.7529][l2: 0.2461][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.78  ]\n",
      "testcase: 73  [l3: 0.7451][l2: 0.2345][l1: 0.0204][e: 0.001 ] ==> [positive accuracy: 0.746 ][negative accuracy: 0.784 ]\n",
      "testcase: 93  [l3: 0.6866][l2: 0.3127][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.78  ]\n",
      "testcase: 102 [l3: 0.5771][l2: 0.4214][l1: 0.0015][e: 0.001 ] ==> [positive accuracy: 0.746 ][negative accuracy: 0.784 ]\n",
      "testcase: 118 [l3: 0.6802][l2: 0.3186][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.78  ]\n",
      "testcase: 122 [l3: 0.6984][l2: 0.3   ][l1: 0.0016][e: 0.001 ] ==> [positive accuracy: 0.752 ][negative accuracy: 0.778 ]\n",
      "testcase: 139 [l3: 0.659 ][l2: 0.3403][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.782 ]\n",
      "testcase: 143 [l3: 0.5945][l2: 0.4044][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.744 ][negative accuracy: 0.786 ]\n",
      "testcase: 151 [l3: 0.5921][l2: 0.4062][l1: 0.0017][e: 0.001 ] ==> [positive accuracy: 0.744 ][negative accuracy: 0.786 ]\n",
      "testcase: 170 [l3: 0.5801][l2: 0.4193][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.744 ][negative accuracy: 0.786 ]\n",
      "testcase: 173 [l3: 0.7459][l2: 0.2528][l1: 0.0013][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.78  ]\n",
      "testcase: 175 [l3: 0.6392][l2: 0.3599][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.782 ]\n",
      "testcase: 204 [l3: 0.5928][l2: 0.4065][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.744 ][negative accuracy: 0.786 ]\n",
      "testcase: 230 [l3: 0.7529][l2: 0.2458][l1: 0.0013][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.78  ]\n",
      "testcase: 233 [l3: 0.5577][l2: 0.4408][l1: 0.0014][e: 0.001 ] ==> [positive accuracy: 0.744 ][negative accuracy: 0.786 ]\n",
      "testcase: 247 [l3: 0.664 ][l2: 0.3348][l1: 0.0013][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.782 ]\n",
      "testcase: 281 [l3: 0.6013][l2: 0.3981][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.744 ][negative accuracy: 0.786 ]\n",
      "testcase: 331 [l3: 0.6561][l2: 0.343 ][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.782 ]\n",
      "testcase: 350 [l3: 0.5939][l2: 0.4044][l1: 0.0017][e: 0.001 ] ==> [positive accuracy: 0.744 ][negative accuracy: 0.786 ]\n",
      "testcase: 372 [l3: 0.8437][l2: 0.1553][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.744 ][negative accuracy: 0.786 ]\n",
      "testcase: 376 [l3: 0.5968][l2: 0.4021][l1: 0.0011][e: 0.001 ] ==> [positive accuracy: 0.744 ][negative accuracy: 0.786 ]\n",
      "testcase: 377 [l3: 0.5988][l2: 0.4003][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.744 ][negative accuracy: 0.786 ]\n",
      "testcase: 378 [l3: 0.5726][l2: 0.4258][l1: 0.0016][e: 0.001 ] ==> [positive accuracy: 0.746 ][negative accuracy: 0.784 ]\n",
      "testcase: 388 [l3: 0.5501][l2: 0.4487][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.744 ][negative accuracy: 0.786 ]\n",
      "testcase: 392 [l3: 0.5869][l2: 0.4113][l1: 0.0018][e: 0.001 ] ==> [positive accuracy: 0.744 ][negative accuracy: 0.786 ]\n",
      "testcase: 401 [l3: 0.6519][l2: 0.3472][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.782 ]\n",
      "testcase: 422 [l3: 0.8349][l2: 0.1642][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.744 ][negative accuracy: 0.786 ]\n",
      "testcase: 426 [l3: 0.7625][l2: 0.2352][l1: 0.0023][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.782 ]\n",
      "testcase: 450 [l3: 0.6609][l2: 0.3384][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.782 ]\n",
      "testcase: 458 [l3: 0.6538][l2: 0.3455][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.782 ]\n",
      "testcase: 486 [l3: 0.6659][l2: 0.3328][l1: 0.0013][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.782 ]\n",
      "testcase: 496 [l3: 0.7662][l2: 0.2317][l1: 0.0021][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.782 ]\n",
      "testcase: 499 [l3: 0.6595][l2: 0.3392][l1: 0.0013][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.782 ]\n",
      "testcase: 10  [l3: 0.5656][l2: 0.4335][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.742 ][negative accuracy: 0.786 ]\n",
      "testcase: 12  [l3: 0.6914][l2: 0.3075][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.778 ]\n",
      "testcase: 14  [l3: 0.8415][l2: 0.1563][l1: 0.0022][e: 0.001 ] ==> [positive accuracy: 0.742 ][negative accuracy: 0.786 ]\n",
      "testcase: 21  [l3: 0.8465][l2: 0.1526][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.742 ][negative accuracy: 0.786 ]\n",
      "testcase: 26  [l3: 0.578 ][l2: 0.4213][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.744 ][negative accuracy: 0.784 ]\n",
      "testcase: 47  [l3: 0.5651][l2: 0.4326][l1: 0.0023][e: 0.001 ] ==> [positive accuracy: 0.742 ][negative accuracy: 0.786 ]\n",
      "testcase: 150 [l3: 0.6648][l2: 0.3343][l1: 0.0008][e: 0.001 ] ==> [positive accuracy: 0.748 ][negative accuracy: 0.78  ]\n",
      "testcase: 203 [l3: 0.5765][l2: 0.4225][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.744 ][negative accuracy: 0.784 ]\n",
      "testcase: 223 [l3: 0.5901][l2: 0.4055][l1: 0.0044][e: 0.001 ] ==> [positive accuracy: 0.746 ][negative accuracy: 0.782 ]\n",
      "testcase: 250 [l3: 0.5613][l2: 0.4359][l1: 0.0028][e: 0.001 ] ==> [positive accuracy: 0.742 ][negative accuracy: 0.786 ]\n",
      "testcase: 269 [l3: 0.682 ][l2: 0.3167][l1: 0.0013][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.778 ]\n",
      "testcase: 307 [l3: 0.6873][l2: 0.3118][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.778 ]\n",
      "testcase: 357 [l3: 0.5767][l2: 0.4222][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.744 ][negative accuracy: 0.784 ]\n",
      "testcase: 370 [l3: 0.6898][l2: 0.3091][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.778 ]\n",
      "testcase: 403 [l3: 0.5613][l2: 0.438 ][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.742 ][negative accuracy: 0.786 ]\n",
      "testcase: 416 [l3: 0.5829][l2: 0.4151][l1: 0.002 ][e: 0.001 ] ==> [positive accuracy: 0.744 ][negative accuracy: 0.784 ]\n",
      "testcase: 20  [l3: 0.5749][l2: 0.4244][l1: 0.0006][e: 0.001 ] ==> [positive accuracy: 0.742 ][negative accuracy: 0.784 ]\n",
      "testcase: 217 [l3: 0.6869][l2: 0.312 ][l1: 0.0011][e: 0.001 ] ==> [positive accuracy: 0.75  ][negative accuracy: 0.776 ]\n",
      "testcase: 298 [l3: 0.8492][l2: 0.1491][l1: 0.0017][e: 0.001 ] ==> [positive accuracy: 0.74  ][negative accuracy: 0.786 ]\n",
      "testcase: 311 [l3: 0.5713][l2: 0.428 ][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.742 ][negative accuracy: 0.784 ]\n",
      "testcase: 316 [l3: 0.8453][l2: 0.1533][l1: 0.0015][e: 0.001 ] ==> [positive accuracy: 0.74  ][negative accuracy: 0.786 ]\n",
      "testcase: 412 [l3: 0.8351][l2: 0.1626][l1: 0.0023][e: 0.001 ] ==> [positive accuracy: 0.742 ][negative accuracy: 0.784 ]\n",
      "testcase: 468 [l3: 0.8528][l2: 0.1463][l1: 0.0009][e: 0.001 ] ==> [positive accuracy: 0.74  ][negative accuracy: 0.786 ]\n",
      "testcase: 483 [l3: 0.5705][l2: 0.4288][l1: 0.0007][e: 0.001 ] ==> [positive accuracy: 0.742 ][negative accuracy: 0.784 ]\n",
      "testcase: 460 [l3: 0.8588][l2: 0.1399][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.738 ][negative accuracy: 0.78  ]\n",
      "testcase: 8   [l3: 0.8553][l2: 0.1408][l1: 0.0039][e: 0.001 ] ==> [positive accuracy: 0.738 ][negative accuracy: 0.776 ]\n",
      "testcase: 287 [l3: 0.86  ][l2: 0.1384][l1: 0.0016][e: 0.001 ] ==> [positive accuracy: 0.738 ][negative accuracy: 0.776 ]\n",
      "testcase: 490 [l3: 0.8614][l2: 0.1367][l1: 0.0019][e: 0.001 ] ==> [positive accuracy: 0.736 ][negative accuracy: 0.776 ]\n",
      "testcase: 87  [l3: 0.8807][l2: 0.1178][l1: 0.0015][e: 0.001 ] ==> [positive accuracy: 0.73  ][negative accuracy: 0.778 ]\n",
      "testcase: 114 [l3: 0.8815][l2: 0.1174][l1: 0.0011][e: 0.001 ] ==> [positive accuracy: 0.73  ][negative accuracy: 0.778 ]\n",
      "testcase: 208 [l3: 0.8997][l2: 0.0988][l1: 0.0014][e: 0.001 ] ==> [positive accuracy: 0.73  ][negative accuracy: 0.778 ]\n",
      "testcase: 386 [l3: 0.8861][l2: 0.1125][l1: 0.0013][e: 0.001 ] ==> [positive accuracy: 0.73  ][negative accuracy: 0.778 ]\n",
      "testcase: 473 [l3: 0.8791][l2: 0.1197][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.73  ][negative accuracy: 0.778 ]\n",
      "testcase: 479 [l3: 0.8774][l2: 0.1214][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.73  ][negative accuracy: 0.778 ]\n",
      "testcase: 399 [l3: 0.8979][l2: 0.1011][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.73  ][negative accuracy: 0.776 ]\n",
      "testcase: 451 [l3: 0.8699][l2: 0.1277][l1: 0.0024][e: 0.001 ] ==> [positive accuracy: 0.728 ][negative accuracy: 0.778 ]\n",
      "testcase: 492 [l3: 0.897 ][l2: 0.1018][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.73  ][negative accuracy: 0.776 ]\n",
      "testcase: 4   [l3: 0.8931][l2: 0.1058][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.728 ][negative accuracy: 0.776 ]\n",
      "testcase: 7   [l3: 0.8906][l2: 0.1065][l1: 0.0029][e: 0.001 ] ==> [positive accuracy: 0.728 ][negative accuracy: 0.776 ]\n",
      "testcase: 443 [l3: 0.893 ][l2: 0.1057][l1: 0.0013][e: 0.001 ] ==> [positive accuracy: 0.728 ][negative accuracy: 0.776 ]\n",
      "testcase: 478 [l3: 0.8848][l2: 0.1125][l1: 0.0027][e: 0.001 ] ==> [positive accuracy: 0.728 ][negative accuracy: 0.776 ]\n",
      "testcase: 5   [l3: 0.8891][l2: 0.109 ][l1: 0.0019][e: 0.001 ] ==> [positive accuracy: 0.728 ][negative accuracy: 0.774 ]\n",
      "testcase: 349 [l3: 0.8929][l2: 0.1056][l1: 0.0015][e: 0.001 ] ==> [positive accuracy: 0.728 ][negative accuracy: 0.774 ]\n",
      "testcase: 153 [l3: 0.8943][l2: 0.0854][l1: 0.0202][e: 0.001 ] ==> [positive accuracy: 0.722 ][negative accuracy: 0.776 ]\n",
      "testcase: 146 [l3: 0.9226][l2: 0.0759][l1: 0.0015][e: 0.001 ] ==> [positive accuracy: 0.728 ][negative accuracy: 0.768 ]\n",
      "testcase: 196 [l3: 0.9156][l2: 0.0834][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.726 ][negative accuracy: 0.77  ]\n",
      "testcase: 282 [l3: 0.9133][l2: 0.0855][l1: 0.0011][e: 0.001 ] ==> [positive accuracy: 0.726 ][negative accuracy: 0.77  ]\n",
      "testcase: 429 [l3: 0.9124][l2: 0.0865][l1: 0.0011][e: 0.001 ] ==> [positive accuracy: 0.726 ][negative accuracy: 0.77  ]\n",
      "testcase: 89  [l3: 0.917 ][l2: 0.0809][l1: 0.0022][e: 0.001 ] ==> [positive accuracy: 0.724 ][negative accuracy: 0.77  ]\n",
      "testcase: 467 [l3: 0.926 ][l2: 0.0721][l1: 0.0019][e: 0.001 ] ==> [positive accuracy: 0.726 ][negative accuracy: 0.768 ]\n",
      "testcase: 264 [l3: 0.919 ][l2: 0.0755][l1: 0.0054][e: 0.001 ] ==> [positive accuracy: 0.724 ][negative accuracy: 0.768 ]\n",
      "testcase: 346 [l3: 0.9267][l2: 0.0719][l1: 0.0014][e: 0.001 ] ==> [positive accuracy: 0.726 ][negative accuracy: 0.766 ]\n",
      "testcase: 390 [l3: 0.9319][l2: 0.0666][l1: 0.0015][e: 0.001 ] ==> [positive accuracy: 0.722 ][negative accuracy: 0.766 ]\n",
      "testcase: 27  [l3: 0.9357][l2: 0.0631][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.718 ][negative accuracy: 0.766 ]\n",
      "testcase: 481 [l3: 0.9373][l2: 0.0608][l1: 0.0019][e: 0.001 ] ==> [positive accuracy: 0.716 ][negative accuracy: 0.766 ]\n",
      "testcase: 152 [l3: 0.942 ][l2: 0.057 ][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.714 ][negative accuracy: 0.762 ]\n",
      "testcase: 410 [l3: 0.9416][l2: 0.0574][l1: 0.0011][e: 0.001 ] ==> [positive accuracy: 0.714 ][negative accuracy: 0.762 ]\n",
      "testcase: 498 [l3: 0.9469][l2: 0.0508][l1: 0.0023][e: 0.001 ] ==> [positive accuracy: 0.714 ][negative accuracy: 0.76  ]\n",
      "testcase: 256 [l3: 0.9521][l2: 0.0465][l1: 0.0014][e: 0.001 ] ==> [positive accuracy: 0.708 ][negative accuracy: 0.764 ]\n",
      "testcase: 293 [l3: 0.9747][l2: 0.0237][l1: 0.0015][e: 0.001 ] ==> [positive accuracy: 0.706 ][negative accuracy: 0.766 ]\n",
      "testcase: 187 [l3: 0.9705][l2: 0.0259][l1: 0.0036][e: 0.001 ] ==> [positive accuracy: 0.702 ][negative accuracy: 0.768 ]\n",
      "testcase: 106 [l3: 0.9643][l2: 0.0344][l1: 0.0013][e: 0.001 ] ==> [positive accuracy: 0.704 ][negative accuracy: 0.764 ]\n",
      "testcase: 154 [l3: 0.979 ][l2: 0.0199][l1: 0.0011][e: 0.001 ] ==> [positive accuracy: 0.706 ][negative accuracy: 0.762 ]\n",
      "testcase: 218 [l3: 0.958 ][l2: 0.0402][l1: 0.0018][e: 0.001 ] ==> [positive accuracy: 0.702 ][negative accuracy: 0.766 ]\n",
      "testcase: 284 [l3: 0.9543][l2: 0.0378][l1: 0.0078][e: 0.001 ] ==> [positive accuracy: 0.704 ][negative accuracy: 0.764 ]\n",
      "testcase: 421 [l3: 0.9562][l2: 0.0428][l1: 0.001 ][e: 0.001 ] ==> [positive accuracy: 0.702 ][negative accuracy: 0.766 ]\n",
      "testcase: 121 [l3: 0.9577][l2: 0.0409][l1: 0.0014][e: 0.001 ] ==> [positive accuracy: 0.7   ][negative accuracy: 0.766 ]\n",
      "testcase: 200 [l3: 0.958 ][l2: 0.0409][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.7   ][negative accuracy: 0.766 ]\n",
      "testcase: 351 [l3: 0.9603][l2: 0.0322][l1: 0.0075][e: 0.001 ] ==> [positive accuracy: 0.702 ][negative accuracy: 0.762 ]\n",
      "testcase: 358 [l3: 0.9969][l2: 0.0019][l1: 0.0012][e: 0.001 ] ==> [positive accuracy: 0.698 ][negative accuracy: 0.766 ]\n",
      "testcase: 462 [l3: 0.994 ][l2: 0.0044][l1: 0.0015][e: 0.001 ] ==> [positive accuracy: 0.696 ][negative accuracy: 0.766 ]\n",
      "testcase: 210 [l3: 0.9797][l2: 0.0183][l1: 0.002 ][e: 0.001 ] ==> [positive accuracy: 0.704 ][negative accuracy: 0.756 ]\n",
      "testcase: 489 [l3: 0.9884][l2: 0.0064][l1: 0.0051][e: 0.001 ] ==> [positive accuracy: 0.696 ][negative accuracy: 0.758 ]\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "date = datetime.datetime.now().strftime(\"%b-%d-%Y-%H-%M-%S\")\n",
    "output_file_adr = f'./results_{test_case_count}_{date}.txt'\n",
    "with open(output_file_adr, 'w') as result_file_relaxed:\n",
    "    c = {k: v for k, v in sorted(test_dictionary_relaxed.items(), key=lambda item: sum(item[1]), reverse=True)}\n",
    "    for key, v in c.items():\n",
    "        k = list(key[1])\n",
    "        p = 4\n",
    "        line = f'testcase: {key[0]:<4}[l3: {np.round(k[0], 4):<6}][l2: {np.round(k[1], 4):<6}][l1: {np.round(k[2], 4):<6}][e: {np.round(k[3], 4):<6}] ==> [positive accuracy: {np.round(v[0], 4):<6}][negative accuracy: {np.round(v[1], 4):<6}]'\n",
    "        print(line)\n",
    "        result_file_relaxed.write(line + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
